{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd  # Import Pandas for data manipulation using dataframes\n",
    "import numpy as np  # Import Numpy for data statistical analysis\n",
    "import matplotlib.pyplot as plt  # Import matplotlib for data visualisation\n",
    "import seaborn as sns  # Statistical data visualization\n",
    "\n",
    "data = pd.read_csv(\"BreastCancerDetection.csv\")\n",
    "\n",
    "#remove the last column\n",
    "data =data.iloc[:,1:-1]\n",
    "\n",
    "#looking for exceptions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z = np.abs(zscore(data.iloc[:,1:]))\n",
    "data['diagnosis'] = data['diagnosis'].map({'M':1,'B':0})\n",
    "\n",
    "X = data.drop(['diagnosis'],axis=1)\n",
    "y = data['diagnosis']\n",
    "\n",
    "X_standard = X.apply(zscore)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standard, y, test_size = 0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_standard = X.apply(zscore)\n",
    "x_standard.describe()\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_standard, y, test_size=0.3, random_state=1)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "def baseline_model(units1, units2, dropout):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units1, input_shape=(30,), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Dense(units2, activation='relu', activity_regularizer=l2(0.01), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop the training if arriving to good results\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 128)               3968      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 21,633\n",
      "Trainable params: 21,121\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe10b9da200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe10b9da200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 1/13 [=>............................] - ETA: 9s - loss: 3.0229 - accuracy: 0.4375WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe10d4fb320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe10d4fb320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13/13 [==============================] - 1s 77ms/step - loss: 2.4574 - accuracy: 0.7124 - val_loss: 1.6544 - val_accuracy: 0.9667\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.9332 - accuracy: 0.9157 - val_loss: 1.4975 - val_accuracy: 0.9667\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.6389 - accuracy: 0.9462 - val_loss: 1.3912 - val_accuracy: 0.9583\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.4257 - accuracy: 0.9684 - val_loss: 1.2872 - val_accuracy: 0.9750\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2889 - accuracy: 0.9568 - val_loss: 1.2013 - val_accuracy: 0.9667\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1541 - accuracy: 0.9592 - val_loss: 1.1198 - val_accuracy: 0.9750\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0154 - accuracy: 0.9760 - val_loss: 1.0336 - val_accuracy: 0.9750\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9500 - accuracy: 0.9644 - val_loss: 0.9756 - val_accuracy: 0.9750\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8593 - accuracy: 0.9724 - val_loss: 0.9430 - val_accuracy: 0.9583\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.8556 - accuracy: 0.9328 - val_loss: 0.8797 - val_accuracy: 0.9667\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.7480 - accuracy: 0.9741 - val_loss: 0.8300 - val_accuracy: 0.9667\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.9698 - val_loss: 0.7947 - val_accuracy: 0.9667\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.9742 - val_loss: 0.7451 - val_accuracy: 0.9500\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.9836 - val_loss: 0.6952 - val_accuracy: 0.9667\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.9762 - val_loss: 0.6776 - val_accuracy: 0.9583\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.9911 - val_loss: 0.6356 - val_accuracy: 0.9667\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.9762 - val_loss: 0.5970 - val_accuracy: 0.9500\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.9718 - val_loss: 0.5909 - val_accuracy: 0.9583\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.9743 - val_loss: 0.5539 - val_accuracy: 0.9750\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.9874 - val_loss: 0.5272 - val_accuracy: 0.9750\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.9601 - val_loss: 0.4977 - val_accuracy: 0.9750\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.9511 - val_loss: 0.4654 - val_accuracy: 0.9833\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.9749 - val_loss: 0.4622 - val_accuracy: 0.9583\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.9792 - val_loss: 0.4215 - val_accuracy: 0.9500\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.9617 - val_loss: 0.4015 - val_accuracy: 0.9500\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.9942 - val_loss: 0.3807 - val_accuracy: 0.9583\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.9671 - val_loss: 0.3747 - val_accuracy: 0.9583\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.9880 - val_loss: 0.3562 - val_accuracy: 0.9583\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.9894 - val_loss: 0.3419 - val_accuracy: 0.9667\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.9984 - val_loss: 0.3399 - val_accuracy: 0.9583\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.9681 - val_loss: 0.3401 - val_accuracy: 0.9583\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9929 - val_loss: 0.3088 - val_accuracy: 0.9667\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9938 - val_loss: 0.2946 - val_accuracy: 0.9667\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9934 - val_loss: 0.2738 - val_accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9961 - val_loss: 0.2579 - val_accuracy: 0.9667\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9928 - val_loss: 0.2644 - val_accuracy: 0.9583\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9782 - val_loss: 0.2611 - val_accuracy: 0.9583\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9787 - val_loss: 0.2567 - val_accuracy: 0.9583\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9946 - val_loss: 0.2583 - val_accuracy: 0.9583\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9926 - val_loss: 0.2552 - val_accuracy: 0.9583\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9875 - val_loss: 0.2388 - val_accuracy: 0.9667\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 0.9868 - val_loss: 0.2251 - val_accuracy: 0.9667\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1424 - accuracy: 0.9970 - val_loss: 0.2196 - val_accuracy: 0.9583\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9743 - val_loss: 0.2432 - val_accuracy: 0.9500\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.9828 - val_loss: 0.2200 - val_accuracy: 0.9583\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9920 - val_loss: 0.1998 - val_accuracy: 0.9667\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9929 - val_loss: 0.1955 - val_accuracy: 0.9583\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9842 - val_loss: 0.2050 - val_accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1403 - accuracy: 0.9830 - val_loss: 0.1926 - val_accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9912 - val_loss: 0.2041 - val_accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "units1 = 128\n",
    "units2 = 128\n",
    "dropout = 0.25\n",
    " \n",
    "# Fit the model\n",
    "model = baseline_model(units1, units2, dropout)\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=50, \n",
    "                    validation_data=(x_val,y_val), \n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9950\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2041 - accuracy: 0.9583\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2218 - accuracy: 0.9608\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_train, y_train)\n",
    "loss, acc = model.evaluate(x_val, y_val)\n",
    "loss, acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fe10dcc00e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fe10dcc00e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The accuracy is: 0.96\n",
      "f1 score : 0.96 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.array([0 if n <= .5 else 1 for n in y_pred])\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('The accuracy is: %.2f' % acc)\n",
    "print('f1 score : %.2f '% f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        28\n",
      "           1       0.96      0.96      0.96        23\n",
      "\n",
      "    accuracy                           0.96        51\n",
      "   macro avg       0.96      0.96      0.96        51\n",
      "weighted avg       0.96      0.96      0.96        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yuval's Tenserflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(398,)\n",
      "(171, 30)\n",
      "(171,)\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe10dcdf440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe10dcdf440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.6922 - accuracy: 0.6139\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 741us/step - loss: 0.6852 - accuracy: 0.7724\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 714us/step - loss: 0.6649 - accuracy: 0.9240\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 695us/step - loss: 0.6242 - accuracy: 0.9190\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 699us/step - loss: 0.5425 - accuracy: 0.9460\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 685us/step - loss: 0.4235 - accuracy: 0.9492\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 702us/step - loss: 0.3268 - accuracy: 0.9427\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 699us/step - loss: 0.2390 - accuracy: 0.9399\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 721us/step - loss: 0.1817 - accuracy: 0.9546\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 710us/step - loss: 0.1529 - accuracy: 0.9631\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 691us/step - loss: 0.1378 - accuracy: 0.9568\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 707us/step - loss: 0.1000 - accuracy: 0.9693\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 702us/step - loss: 0.0937 - accuracy: 0.9840\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 699us/step - loss: 0.0835 - accuracy: 0.9830\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 694us/step - loss: 0.0878 - accuracy: 0.9833\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 688us/step - loss: 0.0620 - accuracy: 0.9913\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 673us/step - loss: 0.0706 - accuracy: 0.9846\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 691us/step - loss: 0.0556 - accuracy: 0.9904\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 730us/step - loss: 0.0520 - accuracy: 0.9856\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 698us/step - loss: 0.0477 - accuracy: 0.9907\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 734us/step - loss: 0.0652 - accuracy: 0.9850\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 742us/step - loss: 0.0435 - accuracy: 0.9909\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 757us/step - loss: 0.0417 - accuracy: 0.9936\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 701us/step - loss: 0.0419 - accuracy: 0.9944\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 721us/step - loss: 0.0454 - accuracy: 0.9915\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 738us/step - loss: 0.0463 - accuracy: 0.9904\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 732us/step - loss: 0.0564 - accuracy: 0.9862\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 758us/step - loss: 0.0705 - accuracy: 0.9823\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 766us/step - loss: 0.0664 - accuracy: 0.9823\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 731us/step - loss: 0.0515 - accuracy: 0.9897\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 730us/step - loss: 0.0495 - accuracy: 0.9869\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 730us/step - loss: 0.0320 - accuracy: 0.9916\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 710us/step - loss: 0.0397 - accuracy: 0.9861\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 718us/step - loss: 0.0339 - accuracy: 0.9901\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 723us/step - loss: 0.0390 - accuracy: 0.9864\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 712us/step - loss: 0.0211 - accuracy: 0.9971\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 739us/step - loss: 0.0390 - accuracy: 0.9894\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 717us/step - loss: 0.0447 - accuracy: 0.9888\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 720us/step - loss: 0.0365 - accuracy: 0.9929\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 723us/step - loss: 0.0390 - accuracy: 0.9847\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 702us/step - loss: 0.0424 - accuracy: 0.9817\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 707us/step - loss: 0.0279 - accuracy: 0.9935\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 695us/step - loss: 0.0316 - accuracy: 0.9910\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 710us/step - loss: 0.0550 - accuracy: 0.9877\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 718us/step - loss: 0.0574 - accuracy: 0.9835\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 706us/step - loss: 0.0574 - accuracy: 0.9830\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 733us/step - loss: 0.0277 - accuracy: 0.9932\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 670us/step - loss: 0.0257 - accuracy: 0.9944\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 676us/step - loss: 0.0285 - accuracy: 0.9935\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 673us/step - loss: 0.0263 - accuracy: 0.9941\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 667us/step - loss: 0.0327 - accuracy: 0.9921\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 672us/step - loss: 0.0275 - accuracy: 0.9930\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 673us/step - loss: 0.0269 - accuracy: 0.9941\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 687us/step - loss: 0.0331 - accuracy: 0.9890\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 707us/step - loss: 0.0330 - accuracy: 0.9929\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 704us/step - loss: 0.0406 - accuracy: 0.9912\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 732us/step - loss: 0.0366 - accuracy: 0.9869\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 706us/step - loss: 0.0443 - accuracy: 0.9873\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 709us/step - loss: 0.0321 - accuracy: 0.9933\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 693us/step - loss: 0.0310 - accuracy: 0.9912\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 686us/step - loss: 0.0199 - accuracy: 0.9940\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 693us/step - loss: 0.0220 - accuracy: 0.9948\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 683us/step - loss: 0.0265 - accuracy: 0.9934\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 719us/step - loss: 0.0278 - accuracy: 0.9930\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 729us/step - loss: 0.0328 - accuracy: 0.9906\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 720us/step - loss: 0.0287 - accuracy: 0.9890\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 669us/step - loss: 0.0327 - accuracy: 0.9894\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 710us/step - loss: 0.0172 - accuracy: 0.9965\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 692us/step - loss: 0.0202 - accuracy: 0.9943\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 717us/step - loss: 0.0269 - accuracy: 0.9898\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 707us/step - loss: 0.0190 - accuracy: 0.9958\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 664us/step - loss: 0.0409 - accuracy: 0.9888\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 670us/step - loss: 0.0133 - accuracy: 0.9991\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 725us/step - loss: 0.0224 - accuracy: 0.9956\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 755us/step - loss: 0.0347 - accuracy: 0.9905\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 723us/step - loss: 0.0163 - accuracy: 0.9974\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 703us/step - loss: 0.0163 - accuracy: 0.9978\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 718us/step - loss: 0.0196 - accuracy: 0.9964\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 827us/step - loss: 0.0204 - accuracy: 0.9967\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 723us/step - loss: 0.0139 - accuracy: 0.9978\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 722us/step - loss: 0.0228 - accuracy: 0.9951\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 754us/step - loss: 0.0279 - accuracy: 0.9929\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 714us/step - loss: 0.0214 - accuracy: 0.9953\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 760us/step - loss: 0.0158 - accuracy: 0.9973\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 749us/step - loss: 0.0270 - accuracy: 0.9918\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 719us/step - loss: 0.0158 - accuracy: 0.9966\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 712us/step - loss: 0.0236 - accuracy: 0.9923\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 747us/step - loss: 0.0217 - accuracy: 0.9934\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 739us/step - loss: 0.0288 - accuracy: 0.9888\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 750us/step - loss: 0.0214 - accuracy: 0.9931\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 806us/step - loss: 0.0186 - accuracy: 0.9946\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 716us/step - loss: 0.0152 - accuracy: 0.9963\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 751us/step - loss: 0.0145 - accuracy: 0.9971\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 732us/step - loss: 0.0123 - accuracy: 0.9978\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 715us/step - loss: 0.0164 - accuracy: 0.9952\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 731us/step - loss: 0.0106 - accuracy: 0.9980\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 727us/step - loss: 0.0173 - accuracy: 0.9946\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9974\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 816us/step - loss: 0.0272 - accuracy: 0.9888\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 714us/step - loss: 0.0106 - accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe10dc76e10>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_standard = X.apply(zscore)\n",
    "x_standard.describe()\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_standard, y, test_size=0.3, random_state=1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "#units = (30+1)/2\n",
    "# result is binary - 1\n",
    "#X_train shape is (6000,11) \n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu', input_dim = 30))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(x_train, y_train, batch_size = 32, epochs = 100)\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "#y_pred = classifier.predict(X_test)\n",
    "\n",
    "#y_pred = (y_pred > 0.5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fe10dda43b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fe10dda43b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 1)\n",
      "(171,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe107602810>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(y_pred.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       108\n",
      "           1       0.95      0.94      0.94        63\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop - get best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 43\n",
      "Trainable params: 39\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe1086394d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe1086394d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 1/13 [=>............................] - ETA: 14s - loss: 0.6687 - accuracy: 0.6875WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe10a1060e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe10a1060e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6787 - accuracy: 0.6782 - val_loss: 0.6942 - val_accuracy: 0.7250\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.6738 - val_loss: 0.6889 - val_accuracy: 0.7667\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.6910 - val_loss: 0.6831 - val_accuracy: 0.7750\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.7305 - val_loss: 0.6766 - val_accuracy: 0.7833\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7894 - val_loss: 0.6699 - val_accuracy: 0.7917\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.7629 - val_loss: 0.6628 - val_accuracy: 0.8000\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7605 - val_loss: 0.6555 - val_accuracy: 0.8083\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.7922 - val_loss: 0.6496 - val_accuracy: 0.8167\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.8044 - val_loss: 0.6443 - val_accuracy: 0.8250\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.8278 - val_loss: 0.6397 - val_accuracy: 0.8250\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.8332 - val_loss: 0.6341 - val_accuracy: 0.8333\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.8478 - val_loss: 0.6276 - val_accuracy: 0.8250\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.8792 - val_loss: 0.6197 - val_accuracy: 0.8333\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.8597 - val_loss: 0.6118 - val_accuracy: 0.8333\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.8603 - val_loss: 0.6031 - val_accuracy: 0.8417\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.8997 - val_loss: 0.5932 - val_accuracy: 0.8500\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.8703 - val_loss: 0.5855 - val_accuracy: 0.8500\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.8829 - val_loss: 0.5755 - val_accuracy: 0.8500\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.8766 - val_loss: 0.5644 - val_accuracy: 0.8500\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8920 - val_loss: 0.5556 - val_accuracy: 0.8417\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.8863 - val_loss: 0.5451 - val_accuracy: 0.8417\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8688 - val_loss: 0.5332 - val_accuracy: 0.8500\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.9065 - val_loss: 0.5210 - val_accuracy: 0.8500\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.8838 - val_loss: 0.5148 - val_accuracy: 0.8583\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8872 - val_loss: 0.5084 - val_accuracy: 0.8667\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.9146 - val_loss: 0.4971 - val_accuracy: 0.8583\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.9002 - val_loss: 0.4874 - val_accuracy: 0.8583\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.9068 - val_loss: 0.4758 - val_accuracy: 0.8583\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8681 - val_loss: 0.4633 - val_accuracy: 0.8667\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.9314 - val_loss: 0.4529 - val_accuracy: 0.8750\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.9002 - val_loss: 0.4497 - val_accuracy: 0.8750\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.9086 - val_loss: 0.4396 - val_accuracy: 0.8750\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.9111 - val_loss: 0.4279 - val_accuracy: 0.8750\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3614 - accuracy: 0.9189 - val_loss: 0.4204 - val_accuracy: 0.8667\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8622 - val_loss: 0.4187 - val_accuracy: 0.8833\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8906 - val_loss: 0.4072 - val_accuracy: 0.8917\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.9151 - val_loss: 0.3952 - val_accuracy: 0.9000\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.9069 - val_loss: 0.3889 - val_accuracy: 0.9167\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.9195 - val_loss: 0.3790 - val_accuracy: 0.9167\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.9225 - val_loss: 0.3733 - val_accuracy: 0.9167\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.9098 - val_loss: 0.3694 - val_accuracy: 0.9250\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.9252 - val_loss: 0.3517 - val_accuracy: 0.9250\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.9281 - val_loss: 0.3419 - val_accuracy: 0.9167\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3153 - accuracy: 0.9256 - val_loss: 0.3362 - val_accuracy: 0.9167\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.9260 - val_loss: 0.3328 - val_accuracy: 0.9167\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.9327 - val_loss: 0.3318 - val_accuracy: 0.9167\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.9256 - val_loss: 0.3209 - val_accuracy: 0.9167\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.9329 - val_loss: 0.3117 - val_accuracy: 0.9167\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.9183 - val_loss: 0.2998 - val_accuracy: 0.9167\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.9378 - val_loss: 0.2921 - val_accuracy: 0.9167\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.9064\n",
      "-----------------------------------------------new score\n",
      "The accuracy is: 0.91 loss is  0.31 \n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 43\n",
      "Trainable params: 39\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe10a104a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fe10a104a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 1/13 [=>............................] - ETA: 14s - loss: 1.3947 - accuracy: 0.1562WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe10766b3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fe10766b3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 1.3696 - accuracy: 0.1843 - val_loss: 1.3641 - val_accuracy: 0.1333\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.3675 - accuracy: 0.1702 - val_loss: 1.2282 - val_accuracy: 0.1333\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2873 - accuracy: 0.1774 - val_loss: 1.1223 - val_accuracy: 0.1417\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2380 - accuracy: 0.2049 - val_loss: 1.0373 - val_accuracy: 0.1333\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1816 - accuracy: 0.2239 - val_loss: 0.9628 - val_accuracy: 0.1833\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1674 - accuracy: 0.2487 - val_loss: 0.9069 - val_accuracy: 0.2083\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0949 - accuracy: 0.2761 - val_loss: 0.8559 - val_accuracy: 0.2833\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0349 - accuracy: 0.3261 - val_loss: 0.8099 - val_accuracy: 0.3250\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.0072 - accuracy: 0.3187 - val_loss: 0.7700 - val_accuracy: 0.3750\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.9417 - accuracy: 0.3554 - val_loss: 0.7375 - val_accuracy: 0.4333\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.8088 - accuracy: 0.4145 - val_loss: 0.7064 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7857 - accuracy: 0.4264 - val_loss: 0.6848 - val_accuracy: 0.5250\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7276 - accuracy: 0.4725 - val_loss: 0.6680 - val_accuracy: 0.5500\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.5223 - val_loss: 0.6556 - val_accuracy: 0.5583\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.5342 - val_loss: 0.6448 - val_accuracy: 0.5667\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.5661 - val_loss: 0.6340 - val_accuracy: 0.5917\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.6169 - val_loss: 0.6241 - val_accuracy: 0.5917\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.6438 - val_loss: 0.6145 - val_accuracy: 0.6083\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6176 - val_loss: 0.6076 - val_accuracy: 0.6417\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5934 - accuracy: 0.6163 - val_loss: 0.6017 - val_accuracy: 0.6417\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6422 - val_loss: 0.5974 - val_accuracy: 0.6417\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6141 - val_loss: 0.5921 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.6447 - val_loss: 0.5862 - val_accuracy: 0.6667\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.6629 - val_loss: 0.5814 - val_accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.6590 - val_loss: 0.5758 - val_accuracy: 0.6750\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.6552 - val_loss: 0.5697 - val_accuracy: 0.6833\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.6420 - val_loss: 0.5633 - val_accuracy: 0.7000\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.6755 - val_loss: 0.5567 - val_accuracy: 0.7083\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.6995 - val_loss: 0.5501 - val_accuracy: 0.7167\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.6752 - val_loss: 0.5440 - val_accuracy: 0.7167\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.6841 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.6985 - val_loss: 0.5300 - val_accuracy: 0.7750\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7299 - val_loss: 0.5238 - val_accuracy: 0.7750\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7678 - val_loss: 0.5184 - val_accuracy: 0.7750\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.6996 - val_loss: 0.5115 - val_accuracy: 0.7750\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7533 - val_loss: 0.5031 - val_accuracy: 0.8333\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7714 - val_loss: 0.4945 - val_accuracy: 0.8417\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7646 - val_loss: 0.4870 - val_accuracy: 0.8583\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7718 - val_loss: 0.4766 - val_accuracy: 0.8667\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7749 - val_loss: 0.4678 - val_accuracy: 0.8833\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7855 - val_loss: 0.4590 - val_accuracy: 0.8917\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7782 - val_loss: 0.4508 - val_accuracy: 0.9083\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.8104 - val_loss: 0.4422 - val_accuracy: 0.9167\n",
      "Epoch 44/50\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.4760 - accuracy: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-b05da65fbf18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     callbacks=[es])\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1141\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1144\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    340\u001b[0m                          ' Always start with this line.'), None)\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2785\u001b[0m     \u001b[0;31m# if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__delattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2730\u001b[0m     \u001b[0;31m# should clean it out to avoid leaking memory. First we check if there are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2731\u001b[0m     \u001b[0;31m# other attributes referencing it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2732\u001b[0;31m     \u001b[0mreference_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_reference_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2733\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexisting_value\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreference_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_obj_reference_counts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2699\u001b[0m     \u001b[0;34m\"\"\"A dictionary counting the number of attributes referencing an object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m     self._maybe_create_attribute('_obj_reference_counts_dict',\n\u001b[0;32m-> 2701\u001b[0;31m                                  object_identity.ObjectIdentityDictionary())\n\u001b[0m\u001b[1;32m   2702\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_reference_counts_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    324\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_self_setattr_tracking'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#def baseline_model(units1, units2, dropout):\n",
    "\n",
    "best_i=1\n",
    "best_j=1\n",
    "best_d=1\n",
    "best_loss=1.0\n",
    "best_acc=0.0\n",
    "\n",
    "for i in range(1,128):\n",
    "    for j in range(1,128):\n",
    "        for d in range(1,100,5):\n",
    "            model= baseline_model(i, j, d/100)\n",
    "            history = model.fit(x_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=50, \n",
    "                    validation_data=(x_val,y_val), \n",
    "                    callbacks=[es])\n",
    "            \n",
    "#            \n",
    "            loss, acc = model.evaluate(x_test, y_test)\n",
    "            \n",
    "            if(best_loss>loss and best_acc<acc):\n",
    "                best_loss=loss \n",
    "                best_acc=acc\n",
    "                best_i=i\n",
    "                best_j=j\n",
    "                best_d=d\n",
    "                print(\"-----------------------------------------------new score\")\n",
    "                print('The accuracy is: %.2f loss is  %.2f ' %(acc,loss)) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 6\n",
      "best results 1 1 1 0.31437116861343384 0.9064327478408813\n"
     ]
    }
   ],
   "source": [
    "print(i,j,d)\n",
    "print(\"best results\", \n",
    "best_i,\n",
    "best_j,\n",
    "best_d,\n",
    "best_loss,\n",
    "best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# removing exceptional data and checking again the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutting first column\n",
    "data2=data.iloc[:,1:]\n",
    "chart = sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(data2))\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "z0 = data2.apply(zscore)\n",
    "z = np.abs(zscore(data2))\n",
    "z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0]\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing exeptional points\n",
    "z_in = (np.abs(zscore(data2)) < 3)\n",
    "data_clean = data2[z_in.all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNNClassifier - Doent Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('soldgame': conda)",
   "language": "python",
   "name": "python37764bitsoldgameconda7262750cf6184ac8bf201f1ff27a4c4f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
