{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Predicting if the cancer diagnosis is benign or malignant based on several observations/features \n",
    "\n",
    "\n",
    "- 30 features are used, examples:\n",
    "        - radius (mean of distances from center to points on the perimeter)\n",
    "        - texture (standard deviation of gray-scale values)\n",
    "        - perimeter\n",
    "        - area\n",
    "        - smoothness (local variation in radius lengths)\n",
    "        - compactness (perimeter^2 / area - 1.0)\n",
    "        - concavity (severity of concave portions of the contour)\n",
    "        - concave points (number of concave portions of the contour)\n",
    "        - symmetry \n",
    "        - fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "- Datasets are linearly separable using all 30 input features\n",
    "- Number of Instances: 569\n",
    "- Class Distribution: 212 Malignant, 357 Benign\n",
    "- Target class:\n",
    "         - Malignant\n",
    "         - Benign\n",
    "         \n",
    "         \n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQjuiDaPbVi3jtsh-uepYaqpN-iX3SuDAmiIg&usqp=CAU=\" width=900 height=900 />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd  # Import Pandas for data manipulation using dataframes\n",
    "import numpy as np  # Import Numpy for data statistical analysis\n",
    "import matplotlib.pyplot as plt  # Import matplotlib for data visualisation\n",
    "import seaborn as sns  # Statistical data visualization\n",
    "# %matplotlib inline\n",
    "\n",
    "# Import Cancer data drom the Sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File BreastCancerDetection.csv does not exist: 'BreastCancerDetection.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dd7608f78b05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BreastCancerDetection.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/soldgame/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File BreastCancerDetection.csv does not exist: 'BreastCancerDetection.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"BreastCancerDetection.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove id and Unnamed: 32\n",
    "data=data.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['diagnosis'], label = \"Count\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue = 'diagnosis', vars = ['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'fractal_dimension_mean',] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue = 'diagnosis', vars = [\n",
    "       'area_mean', 'smoothness_mean', ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'area_mean', y = 'smoothness_mean', hue = 'diagnosis', data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the correlation between the variables \n",
    "# Strong correlation between the mean radius and mean perimeter, mean area and mean primeter\n",
    "plt.figure(figsize=(20,10)) \n",
    "sns.heatmap(data.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 12\n",
    "features_selection = ['radius_mean', 'perimeter_mean', 'area_mean', 'concavity_mean', 'concave points_mean']\n",
    "features_mean= list(data.columns[1:11])\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "for i, feature in enumerate(features_mean):\n",
    "    rows = int(len(features_mean)/2)\n",
    "    \n",
    "    plt.subplot(rows, 2, i+1)\n",
    "    \n",
    "    sns.distplot(data[data['diagnosis']=='M'][feature], bins=bins, color='red', label='M');\n",
    "    sns.distplot(data[data['diagnosis']=='B'][feature], bins=bins, color='blue', label='B');\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i, feature in enumerate(features_mean):\n",
    "    rows = int(len(features_mean)/2)\n",
    "    \n",
    "    plt.subplot(rows, 2, i+1)\n",
    "    \n",
    "    sns.boxplot(x='diagnosis', y=feature, data=data, palette=\"Set1\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking for exceptions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z = np.abs(zscore(data.iloc[:,1:]))\n",
    "\n",
    "X = data.drop(['diagnosis'],axis=1)\n",
    "y = data['diagnosis']\n",
    "\n",
    "X_standard = X.apply(zscore)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = svc_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_predict = svc_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "sns.heatmap(cm, annot=True)\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=4)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "cm = confusion_matrix(y_test, grid_predictions)\n",
    "sns.heatmap(cm, annot=True)\n",
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_area_mean = data['area_mean']\n",
    "X_smoothness_mean=data[\"smoothness_mean\"]\n",
    "X_radius_mean= data[\"radius_mean\"]\n",
    "y = data['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train,y_train)\n",
    "feature_importances = pd.DataFrame(decision_tree.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_predict_train = decision_tree.predict(X_train)\n",
    "y_predict_train\n",
    "cm = confusion_matrix(y_train, y_predict_train)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_predict_test = decision_tree.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict_test)\n",
    "sns.heatmap(cm, annot=True)\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForest = RandomForestClassifier(n_estimators=150)\n",
    "RandomForest.fit(X_train, y_train)\n",
    "\n",
    "y_predict_train = RandomForest.predict(X_train)\n",
    "y_predict_train\n",
    "cm = confusion_matrix(y_train, y_predict_train)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_predict_test = RandomForest.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict_test)\n",
    "sns.heatmap(cm, annot=True)\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data['diagnosis'] = data['diagnosis'].map({'M':1,'B':0})\n",
    "y = data['diagnosis']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standard, y, test_size=0.2)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "NB_classifier = GaussianNB()\n",
    "NB_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train = NB_classifier.predict(X_train)\n",
    "y_predict_train\n",
    "cm = confusion_matrix(y_train, y_predict_train)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_predict_test = NB_classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict_test)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train = classifier.predict(X_train)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cm = confusion_matrix(y_train, y_predict_train)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_test = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict_test)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network multi layer perspetron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "try_model = MLPClassifier()\n",
    "\n",
    "# Fit model\n",
    "try_model.fit(X_train, y_train)\n",
    "\n",
    "#check prediction\n",
    "y_predict = try_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bernuli&linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "logistic = linear_model.LogisticRegression(solver='newton-cg', tol=1)\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "rbm_features_classifier = Pipeline(\n",
    "    steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "\n",
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 10\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "logistic.C = 6000\n",
    "\n",
    "# Fit model\n",
    "rbm_features_classifier.fit(X_train, y_train)\n",
    "\n",
    "#check prediction\n",
    "y_predict = rbm_features_classifier.predict(X_test)\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(y_test, y_predict)))\n",
    "\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "#accuracy and f1\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "acc = accuracy_score(y_test, y_predict)\n",
    "f1 = f1_score(y_test, y_predict, average='macro')\n",
    "f'The accuracy is %.2f     The f1_score is %.2f' % (acc,f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Decent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "accuracy_selection=[]\n",
    "cvs_selection=[]\n",
    "\n",
    "clf = SGDClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "accuracy_selection.append(accuracy_score(prediction, y_test))\n",
    "cvs_selection.append(np.mean(scores))\n",
    "\n",
    "print(\"SGD Classifier Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))\n",
    "print(\"Execution time: %s seconds \\n\" % \"{0:.5}\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALISING PCA AND TENSERFLOW PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the diagnosis column to numeric format\n",
    "# data['diagnosis'] = data['diagnosis'].factorize()[0]\n",
    "# # Fill all Null values with zero\n",
    "# data = data.fillna(value=0)\n",
    "# # Store the diagnosis column in a target object and then drop it\n",
    "# target = data['diagnosis']\n",
    "# data = data.drop('diagnosis', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # Principal Component Analysis module\n",
    "from sklearn.manifold import TSNE # TSNE module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dataframe into arrays\n",
    "X = data.values\n",
    "\n",
    "# Invoke the PCA method. Since this is a binary classification problem\n",
    "# let's call n_components = 2\n",
    "pca = PCA(n_components=2)\n",
    "pca_2d = pca.fit_transform(X)\n",
    "\n",
    "# Invoke the TSNE method\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=2000)\n",
    "tsne_results = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the TSNE and PCA visuals side-by-side\n",
    "plt.figure(figsize = (16,11))\n",
    "plt.subplot(121)\n",
    "plt.scatter(pca_2d[:,0],pca_2d[:,1], c = target, \n",
    "            cmap = \"coolwarm\", edgecolor = \"None\", alpha=0.35)\n",
    "plt.colorbar()\n",
    "plt.title('PCA Scatter Plot')\n",
    "plt.subplot(122)\n",
    "plt.scatter(tsne_results[:,0],tsne_results[:,1],  c = target, \n",
    "            cmap = \"coolwarm\", edgecolor = \"None\", alpha=0.35)\n",
    "plt.colorbar()\n",
    "plt.title('TSNE Scatter Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Training set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors\n",
    "\n",
    "# z = np.exp(-X1**2-X2**2)*1.5+0.2\n",
    "\n",
    "# colors = [\"red\", \"blue\"]\n",
    "# cmap= matplotlib.colors.ListedColormap(colors)\n",
    "# boundaries=[z.min(), 0.35, 0.7, 1.05, 1.4, z.max()]\n",
    "\n",
    "# m = plt.contourf(X1, X2, z, levels = boundaries, cmap=cmap)\n",
    "\n",
    "# plt.colorbar(m, spacing=\"proportional\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), cmap = ListedColormap((\"red\",\"blue\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras and Tenserflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_standard = X.apply(zscore)\n",
    "x_standard.describe()\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_standard, y, test_size=0.3, random_state=1)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "def baseline_model(units1, units2, dropout):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units1, input_shape=(30,), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Dense(units2, activation='relu', activity_regularizer=l2(0.01), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop the training if arriving to good results\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units1 = 128\n",
    "units2 = 128\n",
    "dropout = 0.25\n",
    " \n",
    "# Fit the model\n",
    "model = baseline_model(units1, units2, dropout)\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=50, \n",
    "                    validation_data=(x_val,y_val), \n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_train, y_train)\n",
    "loss, acc = model.evaluate(x_val, y_val)\n",
    "loss, acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.array([0 if n <= .5 else 1 for n in y_pred])\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('The accuracy is: %.2f' % acc)\n",
    "print('f1 score : %.2f '% f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yuval's Tenserflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_standard = X.apply(zscore)\n",
    "x_standard.describe()\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_standard, y, test_size=0.3, random_state=1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "#units = (30+1)/2\n",
    "# result is binary - 1\n",
    "#X_train shape is (6000,11) \n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu', input_dim = 30))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(x_train, y_train, batch_size = 32, epochs = 100)\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "#y_pred = classifier.predict(X_test)\n",
    "\n",
    "#y_pred = (y_pred > 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(y_pred.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop - Get best paramiters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #def baseline_model(units1, units2, dropout):\n",
    "\n",
    "# best_i=1\n",
    "# best_j=1\n",
    "# best_d=1\n",
    "# best_loss=1.0\n",
    "# best_acc=0.0\n",
    "\n",
    "# best_batch_size=1\n",
    "# best_epochs=1\n",
    "\n",
    "# for i in range(1,128):\n",
    "#     for j in range(1,128):\n",
    "#         for d in range(1,100,5):\n",
    "#             model= baseline_model(i, j, d/100)\n",
    "#             history = model.fit(x_train, y_train, \n",
    "#                     batch_size=32, \n",
    "#                     epochs=50, \n",
    "#                     validation_data=(x_val,y_val), \n",
    "#                     callbacks=[es])\n",
    "            \n",
    "# #            \n",
    "#             loss, acc = model.evaluate(x_test, y_test)\n",
    "#             print(\"the best yet are:\")\n",
    "#             print(\"best i %d the best j is %d the best d is %d \" %(best_i,best_j,best_d) )\n",
    "#             print('The best accuracy is: %.2f loss is  %.2f ' %(acc,loss)) \n",
    "            \n",
    "#             if(best_loss>loss and best_acc<acc):\n",
    "#                 best_loss=loss \n",
    "#                 best_acc=acc\n",
    "#                 best_i=i\n",
    "#                 best_j=j\n",
    "#                 best_d=d\n",
    "#                 print(\"-----------------------------------------------new score\")\n",
    "#                 print('The accuracy is: %.2f loss is  %.2f ' %(acc,loss)) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(i,j,d)\n",
    "# print(\"best results\", \n",
    "# best_i,\n",
    "# best_j,\n",
    "# best_d,\n",
    "# best_loss,\n",
    "# best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# removing exceptional data and checking again the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutting first column\n",
    "data2=data.iloc[:,1:]\n",
    "chart = sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(data2))\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "z0 = data2.apply(zscore)\n",
    "z = np.abs(zscore(data2))\n",
    "z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0]\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing exeptional points\n",
    "z_in = (np.abs(zscore(data2)) < 3)\n",
    "data_clean = data2[z_in.all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.columns\n",
    "y_data = data[cols[1]] #diagnosis\n",
    "le = LabelEncoder()\n",
    "y_data = np.array(le.fit_transform(y_data))\n",
    "y_data[:5], le.classes_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = Variable(torch.from_numpy(x_data.values))\n",
    "y_data = Variable(torch.from_numpy(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(30,16)\n",
    "        self.l2 = torch.nn.Linear(16,4)\n",
    "        self.l3 = torch.nn.Linear(4,1)\n",
    "        \n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x)) \n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred\n",
    "    \n",
    "model = Model()\n",
    "y_pred = model(x_data.float())\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.float().size(), y_data.float().size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epochs in range(500):\n",
    "    y_pred = model(x_data.float())\n",
    "    loss = criterion(y_pred, y_data.view(-1,1).float())\n",
    "    print('Epoch',epochs,'Loss:',loss.item(), '- Pred:', y_pred.data[0])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "#The error function is the function representing the difference between the values \n",
    "#computed by your model and the real values. In the optimization field often they\n",
    "#speak about two phases: a training phase in which the model is set,\n",
    "#and a test phase in which the model tests its behaviour against the real values of output.\n",
    "#In the training phase the error is necessary to improve the model, \n",
    "#while in the test phase the error is useful to check if the model works properly.\n",
    "\n",
    "#The objective function is the function you want to maximize or minimize. \n",
    "#When they call it \"cost function\" (again, it's the objective function)\n",
    "#it's because they want to only minimize it. \n",
    "#I see the cost function and the objective function as the same thing seen from slightly \n",
    "#different perspectives.\n",
    "\n",
    "#The \"criterion\" is usually the rule for stopping the algorithm you're using.\n",
    "#Suppose you want that your model find the minimum of an objective function,\n",
    "#in real experiences it is often hard to find the exact minimum and the algorithm \n",
    "#could continuing to work for a very long time. In that case you could accept to \n",
    "#stop it \"near\" to the optimum with a particular stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.data[0]>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.double().forward(x_data.data[25]) > 0.5, y_data[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.double().forward(x_data.data[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.data[25]>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.double().forward(x_data.data[55]) > 0.5, y_data[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.double().forward(x_data) > 0.5\n",
    "pred.numpy()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pred.numpy()\n",
    "b = y_data.numpy()\n",
    "pred.numpy().reshape(-1).shape, y_data.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "c = confusion_matrix(a,b)\n",
    "sns.heatmap(c, annot=True, xticklabels=le.classes_, yticklabels=le.classes_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diagnosis']=np.where(data['diagnosis']=='M',1,0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:, 2:-1].values\n",
    "y=data.iloc[:, 1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.FloatTensor(X_train)\n",
    "X_test=torch.FloatTensor(X_test)\n",
    "y_train=torch.LongTensor(y_train)\n",
    "y_test=torch.LongTensor(y_test)\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self,input_features=30,hidden1=100,hidden2=100,out_features=2):\n",
    "        super().__init__()\n",
    "        self.f_connected1=nn.Linear(input_features,hidden1)\n",
    "        self.f_connected2=nn.Linear(hidden1,hidden2)\n",
    "        self.out=nn.Linear(hidden2,out_features)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.f_connected1(x))\n",
    "        x=F.relu(self.f_connected2(x))\n",
    "        x=self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(20)\n",
    "model=ANN_Model()\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1000\n",
    "final_losses=[]\n",
    "for i in range(epochs):\n",
    "    i=i+1\n",
    "    y_pred=model.forward(X_train)\n",
    "    loss=loss_function(y_pred,y_train)\n",
    "    final_losses.append(loss)\n",
    "    if i%10==1:\n",
    "        print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_losses[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(epochs),final_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test):\n",
    "        y_pred=model(data)\n",
    "        predictions.append(y_pred.argmax().item())\n",
    "        print(y_pred.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,predictions)\n",
    "sns.heatmap(cm, annot=True, xticklabels=le.classes_, yticklabels=le.classes_);\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_test,predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Neural Net from First Principals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's normalized our feature vector.  We will force the mean of each column to 0, and divide by the maximum\n",
    "X_mean = np.mean(X,axis=1,keepdims=True) #Find the mean of each feature\n",
    "X_max = np.max(X,axis=1,keepdims=True) #Find the maximum of each feature\n",
    "X_normalized = (X-X_mean)/(X_max) #Normalizing our dataset by subtracting the mean and dividing by the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's split our dataset into two segments\n",
    "# 1) Training set to train our neural net\n",
    "# 2) A cross validation set to test the accuracy of our neural net\n",
    "\n",
    "#We'll take the first 380 samples for our training set\n",
    "X_train = X_normalized[:,:380]\n",
    "Y_train = Y[:,:380]\n",
    "\n",
    "#We will take the remaining 189 for our cross-validation set\n",
    "X_cv = X_normalized[:,381:]\n",
    "Y_cv = Y[:,381:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now define our sigmoid function to be used in the output layer of our neural network (L3)\n",
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now define our tanh(x) function to be used in hidden layers of our neural network (L1, L2)\n",
    "#Note that the tanh(x) function allows better centering of data than the sigmoid function.  This is why it will be used in our hidden layers.\n",
    "\n",
    "def tanh(z):\n",
    "    s = (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's define our forward propogation function.\n",
    "def forward_prop(X,W1,W2,W3,b1,b2,b3):\n",
    "    \n",
    "    #First layer forward propogation\n",
    "    Z1 = np.dot(W1,X)# where W1 represents our matrix of weights in L1, and X represents our feature matrix of measures\n",
    "    A1 = tanh(Z1 + b1) #where b1 represents our intercept term for our first layer\n",
    "    #Second layer forward propogation\n",
    "    Z2 = np.dot(W2,A1) #where W2 represents our matrix of weights in L2\n",
    "    A2 = tanh(Z2 + b2) # where b2 represents our intercept term for our second layer\n",
    "    #Third layer forward propogation\n",
    "    Z3 = np.dot(W3,A2) #where W3 represents our matrix of weights in L3\n",
    "    #where b3 represents our intercept term for our second layer\n",
    "    A3 = sigmoid(Z3 + b3) #A3 will produce our probability vector\n",
    "    \n",
    "    cache = {    \n",
    "                  \"Z1\": Z1,\n",
    "                  \"A1\": A1,\n",
    "                  \"Z2\": Z2,\n",
    "                  \"A2\": A2,\n",
    "                  \"Z3\": Z3,\n",
    "                  \"A3\": A3\n",
    "            }\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will perform gradient descent for our neural network in the following steps:\n",
    "#1) Start by randomly initializing our weight and intercept parameters\n",
    "#2) Run forward propogation through our neural network\n",
    "#3) Calculate the derivatives of our weights and intercept parameters via back propogation\n",
    "#4) Refine our parameters using derivatives from (3)\n",
    "#5) Reiterate 1 - 4 \n",
    "\n",
    "def gradient_descent(iterations,X,Y,alpha):\n",
    "    \n",
    "    #Randomly initialized our parameters before running the algorithm\n",
    "    W1 = np.random.randn(3,30)*0.01\n",
    "    b1 = np.random.rand(3,1)\n",
    "    W2 = np.random.randn(2,3)*0.01\n",
    "    b2 = np.random.rand(2,1)\n",
    "    W3 = np.random.rand(1,2)*0.01\n",
    "    b3 = np.random.rand(1,1)\n",
    "    dummy,m = X.shape\n",
    "    \n",
    "    caches = [] #we will store our cost at each iteration in this array\n",
    "    count_vector = [] #We will store our iteration count in this array\n",
    "    count = 0\n",
    "    \n",
    "    for i in range (1,iterations):\n",
    "        \n",
    "            count = count + 1\n",
    "            \n",
    "            count_vector.append(count)\n",
    "        \n",
    "            params = forward_prop(X,W1,W2,W3,b1,b2,b3) #forward propogation using our parameters\n",
    "            \n",
    "            #Define our values to be used in back propogation using the dictionary of values created from running forward_prop\n",
    "            Z1 = params['Z1']\n",
    "            Z2 = params['Z2']\n",
    "            Z3 = params['Z3']\n",
    "            A1 = params['A1']\n",
    "            A2 = params['A2']\n",
    "            A3 = params['A3']\n",
    "            \n",
    "            #Define our cost function, append the cost of each iteration to caches\n",
    "            cost = -(1 / m)*np.sum(np.multiply(Y,np.log(A3)) + np.multiply((1-Y),np.log(1-A3)))\n",
    "            caches.append(cost)\n",
    "            \n",
    "            #Back propogation for layer 3\n",
    "            dA3 = -Y/A3 + (1-Y)/(1-A3)\n",
    "            dZ3 = dA3 * sigmoid(Z3)*(1-sigmoid(Z3))\n",
    "            dW3 = (1 / m)*np.dot(dZ3,A2.T)\n",
    "            db3 = (1 / m)*np.sum(dZ3,axis=1,keepdims=True)\n",
    "            \n",
    "            #Back propogation for layer 2\n",
    "            dA2 = np.dot(W3.T,dZ3)\n",
    "            dZ2 = dA2*(1-np.power(tanh(Z2),2))\n",
    "            dW2 = (1 / m)*np.dot(dZ2,A1.T)\n",
    "            db2 = (1 / m)*np.sum(dZ2,axis=1,keepdims=True)\n",
    "            \n",
    "            #Back propogation for layer 1\n",
    "            dA1 = np.dot(W2.T,dZ2)\n",
    "            dZ1 = dA1*(1-np.power(tanh(Z1),2))\n",
    "            dW1 = (1 / m)*np.dot(dZ1,X.T)\n",
    "            db1 = (1 / m)*np.sum(dZ1,axis=1,keepdims=True)\n",
    "            \n",
    "            #Redefine our weight parameters using the derivatives calculated in back propogation\n",
    "            W1 = W1 - alpha*dW1\n",
    "            W2 = W2 - alpha*dW2\n",
    "            W3 = W3 - alpha*dW3\n",
    "            \n",
    "            #Redefine our weight parameters using the derivatives calculated in back propogation\n",
    "            b1 = b1 - alpha*db1\n",
    "            b2 = b2 - alpha*db2\n",
    "            b3 = b3 - alpha*db3\n",
    "        \n",
    "    return W1,W2,W3,b1,b2,b3,count_vector,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see if our algorithm is working.  We should see a declining learning curve with iteration, which eventually flatterns out\n",
    "#This will help us determine the appropriate number of iterations to run to determine the appropriate parameters\n",
    "#Note: we will use a learning rate of 0.5 for now\n",
    "\n",
    "W1,W2,W3,b1,b2,b3,count,caches = gradient_descent(1000,X_cv,Y_cv,0.5)\n",
    "\n",
    "plt.plot(count,caches,label='Cost')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "\n",
    "plt.title(\"Cost vs. Iteration\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,Y,iterations,alpha,X_train,Y_train):\n",
    "\n",
    "    W1,W2,W3,b1,b2,b3,count,caches = gradient_descent(iterations,X_train,Y_train,alpha)\n",
    "    \n",
    "    Z1 = np.dot(W1,X)\n",
    "    A1 = tanh(Z1 + b1)\n",
    "    Z2 = np.dot(W2,A1)\n",
    "    A2 = tanh(Z2 + b2)\n",
    "    Z3 = np.dot(W3,A2)\n",
    "    A3 = sigmoid(Z3 + b3)\n",
    "    \n",
    "    dummy,m = A3.shape\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    \n",
    "    for i in range(m):\n",
    "        \n",
    "        Y_prediction[0, i] = 1 if A3[0, i] > 0.5 else 0\n",
    "        \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how accurate the predictions made by our neural network are compared to the training set and cross validation set\n",
    "print(\"Train accuracy: {} %\".format(100 - np.mean(np.abs(predict(X_train,Y_train,1000,0.5,X_train,Y_train) - Y_train)) * 100))\n",
    "print(\"Cross validation accuracy: {} %\".format(100 - np.mean(np.abs(predict(X_cv,Y_cv,1000,0.5,X_train,Y_train) - Y_cv)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy,m1 = X_train.shape\n",
    "dummy,m2 = X_cv.shape\n",
    "\n",
    "train_predict = predict(X_train,Y_train,1000,0.5,X_train,Y_train)\n",
    "CV_predict = predict(X_cv,Y_cv,1000,0.5,X_train,Y_train)\n",
    "count_true_pos = 0\n",
    "count_train_pos = 0\n",
    "\n",
    "count_true_pos_cv = 0\n",
    "count_cv_pos = 0\n",
    "\n",
    "for i in range (1,m1):\n",
    "    if train_predict[0,i] == 1 and Y_train[0,i] == 1:\n",
    "        count_true_pos = count_true_pos + 1\n",
    "    if Y_train[0,i] == 1:\n",
    "        count_train_pos = count_train_pos + 1\n",
    "        \n",
    "for i in range (1,m2):\n",
    "    if CV_predict[0,i] == 1 and Y_cv[0,i] == 1:\n",
    "        count_true_pos_cv = count_true_pos_cv + 1\n",
    "    if Y_cv[0,i] == 1:\n",
    "        count_cv_pos = count_cv_pos + 1\n",
    "        \n",
    "print(str(count_true_pos) + \" positives predicted on the training set\")\n",
    "print(str(count_train_pos) + \" true positives are in the training set\")\n",
    "print(\"The accuracy of true positives on the training set is: {} %\".format(100-np.abs(100*((count_true_pos - count_train_pos)/count_train_pos))))\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(str(count_true_pos_cv) + \" positives predicted on the cross validation set\")\n",
    "print(str(count_cv_pos) + \" true positives are in the cross validation set\")\n",
    "print(\"The accuracy of true positives on the cross validation set is: {} %\".format(100-np.abs(100*((count_true_pos_cv - count_cv_pos)/count_true_pos_cv))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_true_neg = 0\n",
    "count_train_neg = 0\n",
    "\n",
    "count_true_neg_cv = 0\n",
    "count_cv_neg = 0\n",
    "\n",
    "for i in range (1,m1):\n",
    "    if train_predict[0,i] == 0 and Y_train[0,i] == 0:\n",
    "        count_true_neg = count_true_neg + 1\n",
    "    if Y_train[0,i] == 0:\n",
    "        count_train_neg = count_train_neg + 1\n",
    "        \n",
    "for i in range (1,m2):\n",
    "    if CV_predict[0,i] == 0 and Y_cv[0,i] == 0:\n",
    "        count_true_neg_cv = count_true_neg_cv + 1\n",
    "    if Y_cv[0,i] == 0:\n",
    "        count_cv_neg = count_cv_neg + 1\n",
    "        \n",
    "print(str(count_true_neg) + \" negatives predicted on the training set\")\n",
    "print(str(count_train_neg) + \" true negatives are in the training set\")\n",
    "print(\"The accuracy of true negatives on the training set is: {} %\".format(100-np.abs(100*((count_true_neg - count_train_neg)/count_train_neg))))\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(str(count_true_neg_cv) + \" negatives predicted on the cross validation set\")\n",
    "print(str(count_cv_neg) + \" true negatives are in the cross validation set\")\n",
    "print(\"The accuracy of true negatives on the cross validation set is: {} %\".format(100-np.abs(100*((count_true_neg_cv - count_cv_neg)/count_true_neg_cv))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('soldgame': conda)",
   "language": "python",
   "name": "python37764bitsoldgameconda7262750cf6184ac8bf201f1ff27a4c4f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
