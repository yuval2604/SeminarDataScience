{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd  # Import Pandas for data manipulation using dataframes\n",
    "import numpy as np  # Import Numpy for data statistical analysis\n",
    "import matplotlib.pyplot as plt  # Import matplotlib for data visualisation\n",
    "import seaborn as sns  # Statistical data visualization\n",
    "\n",
    "data = pd.read_csv(\"BreastCancerDetection.csv\")\n",
    "\n",
    "#remove the last column\n",
    "data =data.iloc[:,1:-1]\n",
    "\n",
    "#looking for exceptions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z = np.abs(zscore(data.iloc[:,1:]))\n",
    "\n",
    "X = data.drop(['diagnosis'],axis=1)\n",
    "y = data['diagnosis']\n",
    "\n",
    "X_standard = X.apply(zscore)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standard, y, test_size = 0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_standard = X.apply(zscore)\n",
    "x_standard.describe()\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_standard, y, test_size=0.3, random_state=1)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "def baseline_model(units1, units2, dropout):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units1, input_shape=(30,), activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Dense(units2, activation='relu', <img src=\"subdirectory/MyImage.png\" width=60 height=60 />\n",
    "=l2(0.01), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop the training if arriving to good results\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units1 = 128\n",
    "units2 = 128\n",
    "dropout = 0.25\n",
    " \n",
    "# Fit the model\n",
    "model = baseline_model(units1, units2, dropout)\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=50, \n",
    "                    validation_data=(x_val,y_val), \n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_train, y_train)\n",
    "loss, acc = model.evaluate(x_val, y_val)\n",
    "loss, acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.array([0 if n <= .5 else 1 for n in y_pred])\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('The accuracy is: %.2f' % acc)\n",
    "print('f1 score : %.2f '% f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yuval's Tenserflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "#units = (30+1)/2\n",
    "# result is binary - 1\n",
    "#X_train shape is (6000,11) \n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu', input_dim = 30))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(x_train, y_train, batch_size = 32, epochs = 100)\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop - get best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def baseline_model(units1, units2, dropout):\n",
    "\n",
    "best_i=1\n",
    "best_j=1\n",
    "best_d=1\n",
    "best_loss=1.0\n",
    "best_acc=0.0\n",
    "\n",
    "for i in range(1,128):\n",
    "    for j in range(1,128):\n",
    "        for d in range(1,100,5):\n",
    "            model= baseline_model(i, j, d/100)\n",
    "            history = model.fit(x_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=50, \n",
    "                    validation_data=(x_val,y_val), \n",
    "                    callbacks=[es])\n",
    "            \n",
    "#            \n",
    "            loss, acc = model.evaluate(x_test, y_test)\n",
    "            \n",
    "            if(best_loss>loss and best_acc<acc):\n",
    "                best_loss=loss \n",
    "                best_acc=acc\n",
    "                best_i=i\n",
    "                best_j=j\n",
    "                best_d=d\n",
    "                print(\"-----------------------------------------------new score\")\n",
    "                print('The accuracy is: %.2f loss is  %.2f ' %(acc,loss)) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i,j,d)\n",
    "print(\"best results\", \n",
    "best_i,\n",
    "best_j,\n",
    "best_d,\n",
    "best_loss,\n",
    "best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# removing exceptional data and checking again the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutting first column\n",
    "data2=data.iloc[:,1:]\n",
    "chart = sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(data2))\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "z0 = data2.apply(zscore)\n",
    "z = np.abs(zscore(data2))\n",
    "z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0]\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing exeptional points\n",
    "z_in = (np.abs(zscore(data2)) < 3)\n",
    "data_clean = data2[z_in.all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNNClassifier - Doent Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('soldgame': conda)",
   "language": "python",
   "name": "python37764bitsoldgameconda7262750cf6184ac8bf201f1ff27a4c4f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
